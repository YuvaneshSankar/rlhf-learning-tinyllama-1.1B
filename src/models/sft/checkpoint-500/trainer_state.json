{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.07692011845698242,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015384023691396484,
      "grad_norm": 2.584967613220215,
      "learning_rate": 2.7649769585253458e-06,
      "loss": 3.3921,
      "step": 10
    },
    {
      "epoch": 0.003076804738279297,
      "grad_norm": 2.1197686195373535,
      "learning_rate": 5.837173579109064e-06,
      "loss": 3.4355,
      "step": 20
    },
    {
      "epoch": 0.004615207107418946,
      "grad_norm": 1.4546103477478027,
      "learning_rate": 8.90937019969278e-06,
      "loss": 3.2477,
      "step": 30
    },
    {
      "epoch": 0.006153609476558594,
      "grad_norm": 1.344617486000061,
      "learning_rate": 1.1981566820276497e-05,
      "loss": 3.1501,
      "step": 40
    },
    {
      "epoch": 0.007692011845698243,
      "grad_norm": 2.066725730895996,
      "learning_rate": 1.5053763440860215e-05,
      "loss": 3.1164,
      "step": 50
    },
    {
      "epoch": 0.009230414214837892,
      "grad_norm": 1.6152411699295044,
      "learning_rate": 1.8125960061443932e-05,
      "loss": 2.7623,
      "step": 60
    },
    {
      "epoch": 0.010768816583977539,
      "grad_norm": 1.8350930213928223,
      "learning_rate": 2.1198156682027652e-05,
      "loss": 2.5937,
      "step": 70
    },
    {
      "epoch": 0.012307218953117188,
      "grad_norm": 2.344829797744751,
      "learning_rate": 2.427035330261137e-05,
      "loss": 2.4205,
      "step": 80
    },
    {
      "epoch": 0.013845621322256836,
      "grad_norm": 4.050056457519531,
      "learning_rate": 2.734254992319509e-05,
      "loss": 2.2338,
      "step": 90
    },
    {
      "epoch": 0.015384023691396485,
      "grad_norm": 2.1490421295166016,
      "learning_rate": 3.0414746543778806e-05,
      "loss": 2.0444,
      "step": 100
    },
    {
      "epoch": 0.016922426060536132,
      "grad_norm": 1.358504056930542,
      "learning_rate": 3.348694316436252e-05,
      "loss": 1.8553,
      "step": 110
    },
    {
      "epoch": 0.018460828429675783,
      "grad_norm": 1.3946998119354248,
      "learning_rate": 3.655913978494624e-05,
      "loss": 1.8513,
      "step": 120
    },
    {
      "epoch": 0.01999923079881543,
      "grad_norm": 2.3798844814300537,
      "learning_rate": 3.963133640552996e-05,
      "loss": 1.7238,
      "step": 130
    },
    {
      "epoch": 0.021537633167955077,
      "grad_norm": 1.6720370054244995,
      "learning_rate": 4.270353302611367e-05,
      "loss": 1.6326,
      "step": 140
    },
    {
      "epoch": 0.023076035537094728,
      "grad_norm": 1.9096741676330566,
      "learning_rate": 4.577572964669739e-05,
      "loss": 1.499,
      "step": 150
    },
    {
      "epoch": 0.024614437906234375,
      "grad_norm": 1.5747382640838623,
      "learning_rate": 4.8847926267281106e-05,
      "loss": 1.3412,
      "step": 160
    },
    {
      "epoch": 0.026152840275374026,
      "grad_norm": 1.592766523361206,
      "learning_rate": 5.192012288786483e-05,
      "loss": 1.3982,
      "step": 170
    },
    {
      "epoch": 0.027691242644513673,
      "grad_norm": 1.6842422485351562,
      "learning_rate": 5.499231950844854e-05,
      "loss": 1.3376,
      "step": 180
    },
    {
      "epoch": 0.02922964501365332,
      "grad_norm": 1.5417200326919556,
      "learning_rate": 5.8064516129032266e-05,
      "loss": 1.2252,
      "step": 190
    },
    {
      "epoch": 0.03076804738279297,
      "grad_norm": 3.287029504776001,
      "learning_rate": 6.113671274961598e-05,
      "loss": 1.315,
      "step": 200
    },
    {
      "epoch": 0.03230644975193262,
      "grad_norm": 1.9193211793899536,
      "learning_rate": 6.42089093701997e-05,
      "loss": 1.2919,
      "step": 210
    },
    {
      "epoch": 0.033844852121072265,
      "grad_norm": 1.1237131357192993,
      "learning_rate": 6.72811059907834e-05,
      "loss": 1.2607,
      "step": 220
    },
    {
      "epoch": 0.035383254490211916,
      "grad_norm": 5.890222072601318,
      "learning_rate": 7.035330261136714e-05,
      "loss": 1.1936,
      "step": 230
    },
    {
      "epoch": 0.036921656859351566,
      "grad_norm": 1.1118741035461426,
      "learning_rate": 7.342549923195085e-05,
      "loss": 1.3291,
      "step": 240
    },
    {
      "epoch": 0.03846005922849121,
      "grad_norm": 1.3041982650756836,
      "learning_rate": 7.649769585253457e-05,
      "loss": 1.1517,
      "step": 250
    },
    {
      "epoch": 0.03999846159763086,
      "grad_norm": 0.8721215128898621,
      "learning_rate": 7.956989247311829e-05,
      "loss": 1.1674,
      "step": 260
    },
    {
      "epoch": 0.04153686396677051,
      "grad_norm": 1.0562869310379028,
      "learning_rate": 8.2642089093702e-05,
      "loss": 1.2735,
      "step": 270
    },
    {
      "epoch": 0.043075266335910155,
      "grad_norm": 1.0866798162460327,
      "learning_rate": 8.571428571428571e-05,
      "loss": 1.2501,
      "step": 280
    },
    {
      "epoch": 0.044613668705049805,
      "grad_norm": 1.4433777332305908,
      "learning_rate": 8.878648233486943e-05,
      "loss": 1.1162,
      "step": 290
    },
    {
      "epoch": 0.046152071074189456,
      "grad_norm": 1.0068490505218506,
      "learning_rate": 9.185867895545315e-05,
      "loss": 1.1211,
      "step": 300
    },
    {
      "epoch": 0.0476904734433291,
      "grad_norm": 1.2410961389541626,
      "learning_rate": 9.493087557603687e-05,
      "loss": 1.1446,
      "step": 310
    },
    {
      "epoch": 0.04922887581246875,
      "grad_norm": 0.9184087514877319,
      "learning_rate": 9.800307219662059e-05,
      "loss": 1.1429,
      "step": 320
    },
    {
      "epoch": 0.0507672781816084,
      "grad_norm": 0.8276410698890686,
      "learning_rate": 0.0001010752688172043,
      "loss": 1.2176,
      "step": 330
    },
    {
      "epoch": 0.05230568055074805,
      "grad_norm": 0.9394607543945312,
      "learning_rate": 0.00010414746543778802,
      "loss": 1.1135,
      "step": 340
    },
    {
      "epoch": 0.053844082919887695,
      "grad_norm": 0.7618582844734192,
      "learning_rate": 0.00010721966205837175,
      "loss": 1.1033,
      "step": 350
    },
    {
      "epoch": 0.055382485289027346,
      "grad_norm": 0.8039534091949463,
      "learning_rate": 0.00011029185867895546,
      "loss": 1.1847,
      "step": 360
    },
    {
      "epoch": 0.056920887658166996,
      "grad_norm": 1.115044355392456,
      "learning_rate": 0.00011336405529953918,
      "loss": 1.1742,
      "step": 370
    },
    {
      "epoch": 0.05845929002730664,
      "grad_norm": 0.9048172235488892,
      "learning_rate": 0.00011643625192012289,
      "loss": 1.214,
      "step": 380
    },
    {
      "epoch": 0.05999769239644629,
      "grad_norm": 0.8437467217445374,
      "learning_rate": 0.00011950844854070662,
      "loss": 1.1377,
      "step": 390
    },
    {
      "epoch": 0.06153609476558594,
      "grad_norm": 0.7477501630783081,
      "learning_rate": 0.00012258064516129034,
      "loss": 1.1254,
      "step": 400
    },
    {
      "epoch": 0.06307449713472559,
      "grad_norm": 0.7767701148986816,
      "learning_rate": 0.00012565284178187405,
      "loss": 1.107,
      "step": 410
    },
    {
      "epoch": 0.06461289950386524,
      "grad_norm": 1.1635019779205322,
      "learning_rate": 0.00012872503840245775,
      "loss": 1.1033,
      "step": 420
    },
    {
      "epoch": 0.06615130187300489,
      "grad_norm": 0.8846574425697327,
      "learning_rate": 0.0001317972350230415,
      "loss": 1.1624,
      "step": 430
    },
    {
      "epoch": 0.06768970424214453,
      "grad_norm": 0.9813984036445618,
      "learning_rate": 0.0001348694316436252,
      "loss": 1.2409,
      "step": 440
    },
    {
      "epoch": 0.06922810661128419,
      "grad_norm": 0.9507609009742737,
      "learning_rate": 0.0001379416282642089,
      "loss": 1.2503,
      "step": 450
    },
    {
      "epoch": 0.07076650898042383,
      "grad_norm": 0.7813093066215515,
      "learning_rate": 0.00014101382488479263,
      "loss": 1.0684,
      "step": 460
    },
    {
      "epoch": 0.07230491134956347,
      "grad_norm": 0.7689453363418579,
      "learning_rate": 0.00014408602150537637,
      "loss": 1.1374,
      "step": 470
    },
    {
      "epoch": 0.07384331371870313,
      "grad_norm": 0.7696683406829834,
      "learning_rate": 0.00014715821812596007,
      "loss": 1.0953,
      "step": 480
    },
    {
      "epoch": 0.07538171608784278,
      "grad_norm": 0.6287794709205627,
      "learning_rate": 0.00015023041474654378,
      "loss": 1.107,
      "step": 490
    },
    {
      "epoch": 0.07692011845698242,
      "grad_norm": 0.8339664340019226,
      "learning_rate": 0.0001533026113671275,
      "loss": 1.1726,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 6501,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3066060081844224.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
